# Data-Efficient Hierarchical Reinforcement Learning
Implementation practice of RL project, the second phase

## Understanding: from vanilla HRL to HIRO

 ### HRL Basic Idea

#### Off-policy vs. On-policy

* Watch this video: [Reinforcement Learning Class: Off-policy vs On-policy](https://www.youtube.com/watch?v=hlhzvQnXdAA)

Basically, off-policy methods update action policy with rollouts generated by a different xx policy...

Previous HRL methods use on-policy algorithm, .... 

HIRO uses off-policy algorithms to improve ???

But using off-policy algorithm also introduces trouble: The high-level policy will generate a different target for lower-policy after it was (high-level policy) updated. HIRO puts forward a straight forward makeup to solve this problem.

### HIRO: XXXX

### Insights: YYYY

## Quickly Understand the Code: structures in this project

### Algorithm Structure

### Implementation Structure

## Try Yourself: how to run this code base from scratch

### Getting Started

### Command-Line Interface

### Checkpoint Feature

### Loggers

### Quick Commands to Run Experiments

## Experiments

### Intro to Launched Experiments

### Training Result

## Project Summary

...

